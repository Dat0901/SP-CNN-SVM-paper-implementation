{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6205d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import  Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import  ToTensor, Compose, Resize, Normalize\n",
    "\n",
    "\n",
    "from dcnn import DCNN\n",
    "from utils import encode_label_from_path, VehicleColorDataset, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be71f4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images:  18246\n",
      "Total Classes:  8\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/datdq/1WorkSpace/Dataset_General/COLOR_TYPE/train\"\n",
    "image_list = glob.glob(os.path.join(path, '**', '*.jpg'), recursive=True)\n",
    "class_list = [encode_label_from_path(item) for item in image_list]\n",
    "print(\"Total Images: \", len(image_list))\n",
    "print(\"Total Classes: \", len(set(class_list)))\n",
    "# Splitting the Dataset\n",
    "x_train, x_test , y_train , y_test = train_test_split(image_list, class_list, train_size= 0.5 , stratify=class_list , shuffle=True, random_state=42)\n",
    "transforms=Compose([Resize((227, 227)), \n",
    "                    ToTensor(),\n",
    "                    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "# Create DataLoader for training and testing datasets\n",
    "train_dataset = VehicleColorDataset( x_train , y_train , transforms)\n",
    "train_data_loader = DataLoader(train_dataset,batch_size=115, shuffle=True, num_workers=4)\n",
    "test_dataset = VehicleColorDataset(x_test, y_test,transforms)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=115, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf8cbd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DCNN(num_classes=8).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
    "epochs = 10\n",
    "logger = Logger(log_dir='logs', name='DCNN_color', chkpt_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ffc959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train | Epoch 0: 100%|██████████| 80/80 [00:20<00:00,  3.98batch/s, loss=0.271]\n",
      "Test | Epoch 0: 100%|██████████| 80/80 [00:08<00:00,  9.54batch/s, accuracy=97.1, loss=0.0926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best accuracy: 0.9710 (prev: 0.0000), saving model...\n",
      "Saving Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train | Epoch 1: 100%|██████████| 80/80 [00:20<00:00,  3.98batch/s, loss=0.0625]\n",
      "Test | Epoch 1: 100%|██████████| 80/80 [00:08<00:00,  9.50batch/s, accuracy=97.8, loss=0.0716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best accuracy: 0.9782 (prev: 0.9710), saving model...\n",
      "Saving Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train | Epoch 2: 100%|██████████| 80/80 [00:19<00:00,  4.02batch/s, loss=0.0389]\n",
      "Test | Epoch 2: 100%|██████████| 80/80 [00:08<00:00,  9.43batch/s, accuracy=98.2, loss=0.062] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best accuracy: 0.9820 (prev: 0.9782), saving model...\n",
      "Saving Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train | Epoch 3: 100%|██████████| 80/80 [00:20<00:00,  3.91batch/s, loss=0.0375]\n",
      "Test | Epoch 3: 100%|██████████| 80/80 [00:08<00:00,  9.50batch/s, accuracy=97.3, loss=0.0773]\n",
      "Train | Epoch 4: 100%|██████████| 80/80 [00:20<00:00,  3.91batch/s, loss=0.0332]\n",
      "Test | Epoch 4: 100%|██████████| 80/80 [00:08<00:00,  9.55batch/s, accuracy=99.1, loss=0.0295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best accuracy: 0.9912 (prev: 0.9820), saving model...\n",
      "Saving Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train | Epoch 5: 100%|██████████| 80/80 [00:20<00:00,  3.98batch/s, loss=0.01]   \n",
      "Test | Epoch 5: 100%|██████████| 80/80 [00:08<00:00,  9.46batch/s, accuracy=99.3, loss=0.0295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best accuracy: 0.9925 (prev: 0.9912), saving model...\n",
      "Saving Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train | Epoch 6: 100%|██████████| 80/80 [00:20<00:00,  3.93batch/s, loss=0.0117] \n",
      "Test | Epoch 6: 100%|██████████| 80/80 [00:08<00:00,  9.59batch/s, accuracy=99.2, loss=0.0352]\n",
      "Train | Epoch 7: 100%|██████████| 80/80 [00:20<00:00,  3.93batch/s, loss=0.0137] \n",
      "Test | Epoch 7: 100%|██████████| 80/80 [00:08<00:00,  9.43batch/s, accuracy=99, loss=0.0345]  \n",
      "Train | Epoch 8: 100%|██████████| 80/80 [00:20<00:00,  3.85batch/s, loss=0.0356]\n",
      "Test | Epoch 8: 100%|██████████| 80/80 [00:08<00:00,  9.60batch/s, accuracy=97.9, loss=0.0701]\n",
      "Train | Epoch 9: 100%|██████████| 80/80 [00:20<00:00,  3.93batch/s, loss=0.0228]\n",
      "Test | Epoch 9: 100%|██████████| 80/80 [00:08<00:00,  9.22batch/s, accuracy=98.6, loss=0.0569]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    with tqdm(train_data_loader, unit=\"batch\") as tepoch:\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        batch_ = 0\n",
    "        for X, y in tepoch:\n",
    "            tepoch.set_description(f\"Train | Epoch {epoch}\")\n",
    "            X, y = X.to('cuda'), y.to('cuda')\n",
    "\n",
    "            pred = model(X)\n",
    "            loss_value = loss_fn(pred, y)\n",
    "\n",
    "            loss_value.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "            running_loss += loss_value.item()\n",
    "            batch_ += 1\n",
    "            tepoch.set_postfix(loss=running_loss / batch_)\n",
    "\n",
    "        logger.log('train_loss', running_loss / batch_)\n",
    "\n",
    "    # === Evaluation ===\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        with tqdm(test_data_loader, unit=\"batch\") as tepoch:\n",
    "            tepoch.set_description(f\"Test | Epoch {epoch}\")\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            n_batch = 0\n",
    "            running_loss = 0\n",
    "\n",
    "            for X, y in tepoch:\n",
    "                X, y = X.to('cuda'), y.to('cuda')\n",
    "                pred = model(X)\n",
    "                loss_value = loss_fn(pred, y)\n",
    "                pred_class = pred.argmax(dim=1)\n",
    "\n",
    "                running_loss += loss_value.item()\n",
    "                correct += (pred_class == y).sum().item()\n",
    "                total += y.size(0)\n",
    "                n_batch += 1\n",
    "\n",
    "                tepoch.set_postfix(\n",
    "                    loss=running_loss / n_batch,\n",
    "                    accuracy=(correct / total) * 100\n",
    "                )\n",
    "\n",
    "            logger.log('test_loss', running_loss / n_batch)\n",
    "            logger.log('test_acc', correct / total)\n",
    "            logger.checkpoint(model, correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a235ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350b1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa79c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
